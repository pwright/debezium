// Metadata created by nebel
//
// ConversionStatus: raw
// ConvertedFromFile: modules/ROOT/pages/connectors/oracle.adoc

[id="debezium-connector-for-oracle"]
= {prodname} Connector for Oracle

:partialsdir: ../../partials/

:context: oracle
:data-collection: table
:mbean-name: {context}
:connector-file: {context}
:connector-name: Oracle
ifdef::community[]
:toc:
:toc-placement: macro
:linkattrs:
:icons: font

toc::[]

[[oracle-overview]]
.Overview
endif::community[]

{prodname}'s Oracle connector captures and records row-level changes that occur in databases on an Oracle server,
including tables that are added while the connector is running.
You can configure the connector to emit change events for specific subsets of schemas and tables, or to ignore, mask, or truncate values in specific columns.

ifdef::community[]
For information about the Oracle Database versions that are compatible with this connector, see the link:https://debezium.io/releases/[{prodname} release overview].
endif::community[]
ifdef::product[]
For information about the Oracle Database versions that are compatible with this connector, see the link:{LinkDebeziumSupportedConfigurations}[{NameDebeziumSupportedConfigurations}].
endif::product[]

{prodname} ingests change events from Oracle by using the native LogMiner database package
ifdef::community[]
 or the https://docs.oracle.com/database/121/XSTRM/xstrm_intro.htm#XSTRM72647[XStream API].
While the connector might work with a variety of Oracle versions and editions, only Oracle EE 12 and 19 have been tested.
endif::community[]
ifdef::product[]
.

Information and procedures for using a {prodname} Oracle connector are organized as follows:

  * xref:how-debezium-oracle-connectors-work[]
  * xref:descriptions-of-debezium-oracle-connector-data-change-events[]
  * xref:how-debezium-oracle-connectors-map-data-types[]
  * xref:setting-up-oracle-to-work-with-debezium[]
  * xref:deployment-of-debezium-oracle-connectors[]
  * xref:monitoring-debezium-oracle-connector-performance[]
  * xref:how-debezium-oracle-connectors-handle-faults-and-problems[]
endif::product[]


include::../../assemblies/debezium-using/assembly-how-debezium-oracle-connectors-work.adoc[leveloffset=+1]


include::../../assemblies/debezium-using/assembly-descriptions-of-debezium-oracle-connector-data-change-events.adoc[leveloffset=+1]


include::../../modules/debezium-using/ref-how-debezium-oracle-connectors-map-data-types.adoc[leveloffset=+1]


include::../../assemblies/debezium-using/assembly-setting-up-oracle-to-work-with-debezium.adoc[leveloffset=+1]


include::../../assemblies/debezium-using/assembly-deployment-of-debezium-oracle-connectors.adoc[leveloffset=+1]


include::../../modules/debezium-using/ref-descriptions-of-debezium-oracle-connector-configuration-properties.adoc[leveloffset=+1]


include::../../assemblies/debezium-using/assembly-monitoring-debezium-oracle-connector-performance.adoc[leveloffset=+1]

[[surrogate-schema-evolution]]
.Surrogate schema evolution

The Oracle connector automatically tracks and applies table schema changes by parsing DDL from the redo logs.
If the DDL parser encounters an incompatible statement, if needed, the connector provides an alternative way to apply the schema change.

By default, the connector stops when it encounters a DDL statement that it cannot parse.
You can use {prodname} link:/documentation/reference/configuration/signalling[signaling] to trigger the update of the database schema from such DDL statements.

The type of the schema update action is `schema-changes`.
This action updates the schema of all tables enumerated in the signal parameters.
The message does not contain the update to the schema.
Instead, it contains the complete new schema structure.

.Action parameters
[cols="3,9",options="header"]
|===
|Name | Description

|`database`
|The name of the Oracle database.

|`schema`
|The name of the schema where changes are applied.

|`changes`
|An array containing the requested schema updates.

|`changes.type`
|Type of the schema change, usually `ALTER`

|`changes.id`
|The fully-qualified name of the table

|`changes.table`
|The fully-qualified name of the table

|`changes.table.defaultCharsetName`
|The character set name used for the table if different from database default

|`changes.table.primaryKeyColumnNames`
|Array with the name of columns composing the primary key

|`changes.table.columns`
|Array with the column metadata

|`...columns.name`
|The name of the column

|`...columns.jdbcType`
|The JDBC type of the column as defined at link:https://docs.oracle.com/javase/8/docs/api/java/sql/Types.html[JDBC API]

|`...columns.typeName`
|The name of the column type

|`...columns.typeExpression`
|The full column type definition

|`...columns.charsetName`
|The column character set if different from the default

|`...columns.length`
|The length/size constraint of the column

|`...columns.scale`
|The scale of numeric column

|`...columns.position`
|The position of the column in the table starting with `1`

|`...columns.optional`
|Boolean `true` if column value is not mandatory

|`...columns.autoIncremented`
|Boolean `true` if column value is automatically calculated from a sequence

|`...columns.generated`
|Boolean `true` if column value is automatically calculated

|===

After the `schema-changes` signal is inserted, the connector must be restarted with an altered configuration that includes specifying the  <<{context}-property-database-history-skip-unparseable-ddl, `+database.history.skip.unparseable.ddl+`>> option as `true`.
After the connector's commit SCN advances beyond the DDL change, to prevent unparseable DDL statements from being skipped unexpectedly, return the connector configuration to its previous state.

.Example of a logging record
[cols="1,9a",options="header"]
|===
|Column | Value

|id
|`924e3ff8-2245-43ca-ba77-2af9af02fa07`

|type
|`schema-changes`

|data
|[source,json,indent=0,subs="attributes"]
----
{
   "database":"ORCLPDB1",
   "schema":"DEBEZIUM",
   "changes":[
      {
         "type":"ALTER",
         "id":"\"ORCLPDB1\".\"DEBEZIUM\".\"CUSTOMER\"",
         "table":{
            "defaultCharsetName":null,
            "primaryKeyColumnNames":[
               "ID",
               "NAME"
            ],
            "columns":[
               {
                  "name":"ID",
                  "jdbcType":2,
                  "typeName":"NUMBER",
                  "typeExpression":"NUMBER",
                  "charsetName":null,
                  "length":9,
                  "scale":0,
                  "position":1,
                  "optional":false,
                  "autoIncremented":false,
                  "generated":false
               },
               {
                  "name":"NAME",
                  "jdbcType":12,
                  "typeName":"VARCHAR2",
                  "typeExpression":"VARCHAR2",
                  "charsetName":null,
                  "length":1000,
                  "position":2,
                  "optional":true,
                  "autoIncremented":false,
                  "generated":false
               },
               {
                  "name":"SCORE",
                  "jdbcType":2,
                  "typeName":"NUMBER",
                  "typeExpression":"NUMBER",
                  "charsetName":null,
                  "length":6,
                  "scale":2,
                  "position":3,
                  "optional":true,
                  "autoIncremented":false,
                  "generated":false
               },
               {
                  "name":"REGISTERED",
                  "jdbcType":93,
                  "typeName":"TIMESTAMP(6)",
                  "typeExpression":"TIMESTAMP(6)",
                  "charsetName":null,
                  "length":6,
                  "position":4,
                  "optional":true,
                  "autoIncremented":false,
                  "generated":false
               }
            ]
         }
      }
   ]
}
----

|===

[[oracle-xstreams-support]]
.XStreams support

The {prodname} Oracle connector by default ingests changes using native Oracle LogMiner.
The connector can be toggled to use Oracle XStream instead.
To configure the connector to use Oracle XStream, you must apply specific database and connector configurations that differ from those that you use with LogMiner.

.Prerequisites

* To use the XStream API, you must have a license for the GoldenGate product.
Installing GoldenGate is not required.

.Preparing the Database

.Configuration needed for Oracle XStream
[source,indent=0]
----
ORACLE_SID=ORCLCDB dbz_oracle sqlplus /nolog

CONNECT sys/top_secret AS SYSDBA
alter system set db_recovery_file_dest_size = 5G;
alter system set db_recovery_file_dest = '/opt/oracle/oradata/recovery_area' scope=spfile;
alter system set enable_goldengate_replication=true;
shutdown immediate
startup mount
alter database archivelog;
alter database open;
-- Should show "Database log mode: Archive Mode"
archive log list

exit;
----

In addition, supplemental logging must be enabled for captured tables or the database in order for data changes to capture the _before_ state of changed database rows.
The following illustrates how to configure this on a specific table, which is the ideal choice to minimize the amount of information captured in the Oracle redo logs.

[source,indent=0]
----
ALTER TABLE inventory.customers ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;
----

.Creating XStream users for the connector

The {prodname} Oracle connector requires that users accounts be set up with specific permissions so that the connector can capture change events.
The following briefly describes these user configurations using a multi-tenant database model.


[[oracle-create-users-xstream]]
.Creating an XStream Administrator user
[source,indent=0]
----
sqlplus sys/top_secret@//localhost:1521/ORCLCDB as sysdba
  CREATE TABLESPACE xstream_adm_tbs DATAFILE '/opt/oracle/oradata/ORCLCDB/xstream_adm_tbs.dbf'
    SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
  exit;

sqlplus sys/top_secret@//localhost:1521/ORCLPDB1 as sysdba
  CREATE TABLESPACE xstream_adm_tbs DATAFILE '/opt/oracle/oradata/ORCLCDB/ORCLPDB1/xstream_adm_tbs.dbf'
    SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
  exit;

sqlplus sys/top_secret@//localhost:1521/ORCLCDB as sysdba
  CREATE USER c##dbzadmin IDENTIFIED BY dbz
    DEFAULT TABLESPACE xstream_adm_tbs
    QUOTA UNLIMITED ON xstream_adm_tbs
    CONTAINER=ALL;

  GRANT CREATE SESSION, SET CONTAINER TO c##dbzadmin CONTAINER=ALL;

  BEGIN
     DBMS_XSTREAM_AUTH.GRANT_ADMIN_PRIVILEGE(
        grantee                 => 'c##dbzadmin',
        privilege_type          => 'CAPTURE',
        grant_select_privileges => TRUE,
        container               => 'ALL'
     );
  END;
  /

  exit;
----

.Creating the connector's XStream user
[source,indent=0]
----
sqlplus sys/top_secret@//localhost:1521/ORCLCDB as sysdba
  CREATE TABLESPACE xstream_tbs DATAFILE '/opt/oracle/oradata/ORCLCDB/xstream_tbs.dbf'
    SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
  exit;

sqlplus sys/top_secret@//localhost:1521/ORCLPDB1 as sysdba
  CREATE TABLESPACE xstream_tbs DATAFILE '/opt/oracle/oradata/ORCLCDB/ORCLPDB1/xstream_tbs.dbf'
    SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
  exit;

sqlplus sys/top_secret@//localhost:1521/ORCLCDB as sysdba
  CREATE USER c##dbzuser IDENTIFIED BY dbz
    DEFAULT TABLESPACE xstream_tbs
    QUOTA UNLIMITED ON xstream_tbs
    CONTAINER=ALL;

  GRANT CREATE SESSION TO c##dbzuser CONTAINER=ALL;
  GRANT SET CONTAINER TO c##dbzuser CONTAINER=ALL;
  GRANT SELECT ON V_$DATABASE to c##dbzuser CONTAINER=ALL;
  GRANT FLASHBACK ANY TABLE TO c##dbzuser CONTAINER=ALL;
  GRANT SELECT_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;
  GRANT EXECUTE_CATALOG_ROLE TO c##dbzuser CONTAINER=ALL;
  exit;
----

.Create an XStream Outbound Server

Create an https://docs.oracle.com/cd/E11882_01/server.112/e16545/xstrm_cncpt.htm#XSTRM1088[XStream Outbound server]
(given the right privileges, this might be done automatically by the connector going forward, see {jira-url}/browse/DBZ-721[DBZ-721]):

.Create an XStream Outbound Server
[source,indent=0]
----
sqlplus c##dbzadmin/dbz@//localhost:1521/ORCLCDB
DECLARE
  tables  DBMS_UTILITY.UNCL_ARRAY;
  schemas DBMS_UTILITY.UNCL_ARRAY;
BEGIN
    tables(1)  := NULL;
    schemas(1) := 'debezium';
  DBMS_XSTREAM_ADM.CREATE_OUTBOUND(
    server_name     =>  'dbzxout',
    table_names     =>  tables,
    schema_names    =>  schemas);
END;
/
exit;
----

[NOTE]
====
When setting up an XStream Outbound Server to capture changes from a pluggable database,
the `source_container_name` parameter should be provided specifying the pluggable database name.
====

.Configure the XStream user account to connect to the XStream Outbound Server
[source,indent=0]
----
sqlplus sys/top_secret@//localhost:1521/ORCLCDB as sysdba
BEGIN
  DBMS_XSTREAM_ADM.ALTER_OUTBOUND(
    server_name  => 'dbzxout',
    connect_user => 'c##dbzuser');
END;
/
exit;
----

[NOTE]
====
A single XStream Outbound server cannot be shared by multiple {prodname} Oracle connectors.
Each connector requires a unique XStream Outbound connector to be configured.
====

[[selecting-the-adapter]]
.Configuring the XStream adapter

By default, {prodname} uses Oracle LogMiner to ingest change events from Oracle.
You can adjust the connector configuration to enable the connector to use the Oracle XStreams adapter.

The following configuration example adds the properties `database.connection.adapter` and `database.out.server.name` to enable the connector to use the XStream API implementation.

[source,json,indent=0]
----
{
    "name": "inventory-connector",
    "config": {
        "connector.class" : "io.debezium.connector.oracle.OracleConnector",
        "tasks.max" : "1",
        "database.server.name" : "server1",
        "database.hostname" : "<oracle ip>",
        "database.port" : "1521",
        "database.user" : "c##dbzuser",
        "database.password" : "dbz",
        "database.dbname" : "ORCLCDB",
        "database.pdb.name" : "ORCLPDB1",
        "database.history.kafka.bootstrap.servers" : "kafka:9092",
        "database.history.kafka.topic": "schema-changes.inventory",
        "database.connection.adapter": "xstream",
        "database.out.server.name" : "dbzxout"
    }
}
----

[id="obtaining-oracle-jdbc-driver-and-xstreams-api-files"]
.Obtaining the Oracle JDBC driver and XStream API files

The {prodname} Oracle connector requires the Oracle JDBC driver (`ojdbc8.jar`) to connect to Oracle databases.
If the connector uses XStream to access the database, you must also have the XStream API (`xstreams.jar`).
Licensing requirements prohibit {prodname} from including these files in the Oracle connector archive.
However, the required files are available for free download as part of the Oracle Instant Client.
The following steps describe how to download the Oracle Instant Client and extract the required files.

.Procedure

. From a browser, download the https://www.oracle.com/database/technologies/instant-client/downloads.html[Oracle Instant Client package] for your operating system.

. Extract the archive, and then open the `instantclient___<version>__` directory.
+
For example:
+
[source]
----
instantclient_21_1/
├── adrci
├── BASIC_LITE_LICENSE
├── BASIC_LITE_README
├── genezi
├── libclntshcore.so -> libclntshcore.so.21.1
├── libclntshcore.so.12.1 -> libclntshcore.so.21.1

...

├── ojdbc8.jar
├── ucp.jar
├── uidrvci
└── xstreams.jar

----

. Copy the `ojdbc8.jar` and `xstreams.jar` files, and add them to the `_<kafka_home>_/libs` directory, for example, `kafka/libs`.
. Create an environment variable, `LD_LIBRARY_PATH`, and set its value to the path to the Instant Client directory, for example:
+
[source,bash,indent=0]
----
LD_LIBRARY_PATH=/path/to/instant_client/
----

[[oracle-xstreams-connector-properties]]
.XStream connector properties

The following configuration properties are _required_ when using XStreams unless a default value is available.

[cols="30%a,25%a,45%a"]
|===
|Property
|Default
|Description

|[[oracle-property-database-out-server-name]]<<oracle-property-database-out-server-name, `+database.out.server.name+`>>
|No default
|Name of the XStream outbound server configured in the database.

|===

[[oracle-xstreams-dbms-lob-package]]
.XStream and DBMS_LOB

Oracle provides a database package called `DBMS_LOB` that consists of a collection of programs to operate on BLOB, CLOB, and NCLOB columns.
Most of these programs manipulate the LOB column in totality, however, one program, `WRITEAPPEND`, is capable of manipulating a subset of the LOB data buffer.

When using XStream, `WRITEAPPEND` emits a logical change record (LCR) event for each invocation of the program.
These LCR events are not combined into a single change event like they are when using the Oracle LogMiner adapter, and so consumers of the topic should be prepared to receive events with partial column values.
This diverged behavior is captured in https://issues.redhat.com/browse/DBZ-4741[DBZ-4741] and will be addressed in a future release.


endif::community[]


include::../../modules/debezium-using/con-how-debezium-oracle-connectors-handle-faults-and-problems.adoc[leveloffset=+1]

