// Metadata created by nebel
//
// ConvertedFromFile: modules/ROOT/pages/connectors/oracle.adoc
// ConversionStatus: raw

[id="deploying-debezium-oracle-connectors"]
= Deploying a {prodname} Oracle connector by building a custom Kafka Connect container image from a Dockerfile

To deploy a {prodname} Oracle connector, you must build a custom Kafka Connect container image that contains the {prodname} connector archive, and then push this container image to a container registry.
You then need to create the following custom resources (CRs):

* A `KafkaConnect` CR that defines your Kafka Connect instance.
  The `image` property in the CR specifies the name of the container image that you create to run your {prodname} connector.
  You apply this CR to the OpenShift instance where link:https://access.redhat.com/products/red-hat-amq#streams[Red Hat {StreamsName}] is deployed.
  {StreamsName} offers operators and images that bring Apache Kafka to OpenShift.

* A `KafkaConnector` CR that defines your {prodname} Oracle connector.
  Apply this CR to the same OpenShift instance where you apply the `KafkaConnect` CR.

.Prerequisites

* Oracle Database is running and you completed the steps to {LinkDebeziumUserGuide}#setting-up-oracle-for-use-with-the-debezium-oracle-connector[set up Oracle to work with a {prodname} connector].

* {StreamsName} is deployed on OpenShift and is running Apache Kafka and Kafka Connect.
  For more information, see link:{LinkDeployStreamsOpenShift}[{NameDeployStreamsOpenShift}]

* Podman or Docker is installed.

* You have an account and permissions to create and manage containers in the container registry (such as `quay.io` or `docker.io`) to which you plan to add the container that will run your {prodname} connector.

* The Kafka Connect server has access to Maven Central to download the required JDBC driver for Oracle.
  You can also use a local copy of the driver, or one that is available from a local Maven repository or other HTTP server.
+
For more information, see xref:{link-oracle-connector}#obtaining-the-oracle-jdbc-driver[Obtaining the Oracle JDBC driver].

.Procedure

. Create the {prodname} Oracle container for Kafka Connect:

.. Create a Dockerfile that uses `{DockerKafkaConnect}` as the base image.
For example, from a terminal window, enter the following command:
+
[source,shell,subs="+attributes,+quotes"]
----
cat <<EOF >debezium-container-for-oracle.yaml // <1>
FROM {DockerKafkaConnect}
USER root:root
RUN mkdir -p /opt/kafka/plugins/debezium // <2>
RUN curl -O {red-hat-maven-repository}debezium/debezium-connector-{connector-file}/{debezium-version}-redhat-__<build_number>__/debezium-connector-{connector-file}-{debezium-version}-redhat-__<build_number>__-plugin.zip
RUN curl -O https://repo1.maven.org/maven2/com/oracle/ojdbc/ojdbc8/{ojdbc8-version}/ojdbc8-{ojdbc8-version}.jar
USER 1001
EOF
----
<1> You can specify any file name that you want.
<2> Specifies the path to your Kafka Connect plug-ins directory. If your Kafka Connect plug-ins directory is in a different location, replace this path with the actual path of your directory.
+
The command creates a Dockerfile with the name `debezium-container-for-oracle.yaml` in the current directory.

.. Build the container image from the `debezium-container-for-oracle.yaml` Docker file that you created in the previous step.
From the directory that contains the file, open a terminal window and enter one of the following commands:
+
[source,shell,options="nowrap"]
----
podman build -t debezium-container-for-oracle:latest .
----
+
[source,shell,options="nowrap"]
----
docker build -t debezium-container-for-oracle:latest .
----
The preceding commands build a container image with the name `debezium-container-for-oracle`.

.. Push your custom image to a container registry, such as quay.io or an internal container registry.
The container registry must be available to the OpenShift instance where you want to deploy the image.
Enter one of the following commands:
+
[source,shell,subs="+quotes"]
----
podman push _<myregistry.io>_/debezium-container-for-oracle:latest
----
+
[source,shell,subs="+quotes"]
----
docker push _<myregistry.io>_/debezium-container-for-oracle:latest
----

.. Create a new {prodname} Oracle KafkaConnect custom resource (CR).
For example, create a KafkaConnect CR with the name `dbz-connect.yaml` that specifies `annotations` and `image` properties as shown in the following example:
+
[source,yaml,subs="+attributes"]
----
apiVersion: {KafkaConnectApiVersion}
kind: KafkaConnect
metadata:
  name: my-connect-cluster
  annotations:
    strimzi.io/use-connector-resources: "true" // <1>
spec:
  #...
  image: debezium-container-for-oracle  // <2>
----
<1>  `metadata.annotations` indicates to the Cluster Operator that KafkaConnector resources are used to configure connectors in this Kafka Connect cluster.
<2>  `spec.image` specifies the name of the image that you created to run your {prodname} connector.
This property overrides the `STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE` variable in the Cluster Operator

.. Apply the `KafkaConnect` CR to the OpenShift Kafka Connect environment by entering the following command:
+
[source,shell,options="nowrap"]
----
oc create -f dbz-connect.yaml
----
+
The command adds a Kafka Connect instance that specifies the name of the image that you created to run your {prodname} connector.

. Create a `KafkaConnector` custom resource that configures your {prodname} Oracle connector instance.
+
You configure a {prodname} Oracle connector in a `.yaml` file that specifies the configuration properties for the connector.
The connector configuration might instruct {prodname} to produce events for a subset of the schemas and tables, or it might set properties so that {prodname} ignores, masks, or truncates values in specified columns that are sensitive, too large, or not needed.
+
The following example configures a {prodname} connector that connects to an Oracle host IP address, on port `1521`.
This host has a database named `ORCLCDB`, and `server1` is the server's logical name.
+
.Oracle `inventory-connector.yaml`
[source,yaml,subs="+attributes,+quotes",options="nowrap"]
----
apiVersion: {KafkaConnectorApiVersion}
kind: KafkaConnector
metadata:
  name: inventory-connector // <1>
  labels:
    strimzi.io/cluster: my-connect-cluster
  annotations:
    strimzi.io/use-connector-resources: 'true'
spec:
  class: io.debezium.connector.oracle.OracleConnector // <2>
  config:
    database.hostname: _<oracle_ip_address>_ // <3>
    database.port: 1521 // <4>
    database.user: c##dbzuser // <5>
    database.password: dbz // <6>
    database.dbname: ORCLCDB // <7>
    database.pdb.name : ORCLPDB1, <8>
    database.server.name: server1 // <9>
    database.history.kafka.bootstrap.servers: kafka:9092 // <10>
    database.history.kafka.topic: schema-changes.inventory // <11>
----
+
.Descriptions of connector configuration settings
[cols="1,7",options="header",subs="+attributes"]
|===
|Item |Description

|1
|The name of our connector when we register it with a Kafka Connect service.

|2
|The name of this Oracle connector class.

|3
|The address of the Oracle instance.

|4
|The port number of the Oracle instance.

|5
|The name of the Oracle user, as specified in xref:{link-oracle-connector}#creating-users-for-the-connector[Creating users for the connector].

|6
|The password for the Oracle user, as specified in xref:{link-oracle-connector}#creating-users-for-the-connector[Creating users for the connector].

|7
|The name of the database to capture changes from.

|8
|The name of the Oracle pluggable database that the connector captures changes from. Used in container database (CDB) installations only.

|9
|Logical name that identifies and provides a namespace for the Oracle database server from which the connector captures changes.

|10
|The list of Kafka brokers that this connector uses to write and recover DDL statements to the database history topic.

|11
|The name of the database history topic where the connector writes and recovers DDL statements. This topic is for internal use only and should not be used by consumers.

|===

. Create your connector instance with Kafka Connect.
  For example, if you saved your `KafkaConnector` resource in the `inventory-connector.yaml` file, you would run the following command:
+
[source,shell,options="nowrap"]
----
oc apply -f inventory-connector.yaml
----
+
The preceding command registers `inventory-connector` and the connector starts to run against the `server1` database as defined in the `KafkaConnector` CR.


