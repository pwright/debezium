// Metadata created by nebel
//
// ConvertedFromTitle: Schema change topic
// ConvertedFromFile: modules/ROOT/pages/connectors/db2.adoc
// ConversionStatus: raw

[id="about-the-debezium-db2-connector-schema-change-topic"]
= About the {prodname} Db2 connector schema change topic

You can configure a {prodname} Db2 connector to produce schema change events that describe schema changes that are applied to captured tables in the database.

{prodname} emits a message to the schema change topic when:

* A new table goes into capture mode.
* A table is removed from capture mode.
* During a xref:{link-db2-connector}#db2-schema-evolution[database schema update], there is a change in the schema for a table that is in capture mode.

The connector writes schema change events to a Kafka schema change topic that has the name `_<serverName>_` where `_<serverName>_` is the logical server name that is specified in the xref:db2-property-database-server-name[`database.server.name`] connector configuration property.
Messages that the connector sends to the schema change topic contain a payload that includes the following elements:

`databaseName`:: The name of the database to which the statements are applied.
The value of `databaseName` serves as the message key.
`pos`:: The position in the binlog where the statements appear.
`tableChanges`::  A structured representation of the entire table schema after the schema change.
The `tableChanges` field contains an array that includes entries for each column of the table.
Because the structured representation presents data in JSON or Avro format, consumers can easily read messages without first processing them through a DDL parser.

[IMPORTANT]
====
For a table that is in capture mode, the connector not only stores the history of schema changes in the schema change topic, but also in an internal database history topic.
The internal database history topic is for connector use only and it is not intended for direct use by consuming applications.
Ensure that applications that require notifications about schema changes consume that information only from the schema change topic.
====

[IMPORTANT]
====
Never partition the database history topic.
For the database history topic to function correctly, it must maintain a consistent, global order of the event records that the connector emits to it.

To ensure that the topic is not split among partitions, set the partition count for the topic by using one of the following methods:

* If you create the database history topic manually, specify a partition count of `1`.
* If you use the Apache Kafka broker to create the database history topic automatically, the topic is created, set the value of the link:{link-kafka-docs}/#brokerconfigs_num.partitions[Kafka `num.partitions`] configuration option to `1`.
====

[WARNING]
====
The format of messages that a connector emits to its schema change topic is in an incubating state and can change without notice.
====

.Example: Message emitted to the Db2 connector schema change topic
The following example shows a message in the schema change topic.
The message contains a logical representation of the table schema.

[source,json,indent=0,subs="+attributes"]
----
{
  "schema": {
  ...
  },
  "payload": {
    "source": {
      "version": "{debezium-version}",
      "connector": "db2",
      "name": "db2",
      "ts_ms": 0,
      "snapshot": "true",
      "db": "testdb",
      "schema": "DB2INST1",
      "table": "CUSTOMERS",
      "change_lsn": null,
      "commit_lsn": "00000025:00000d98:00a2",
      "event_serial_no": null
    },
    "ts_ms": 1588252618953, // <1>
    "databaseName": "TESTDB", // <2>
    "schemaName": "DB2INST1",
    "ddl": null, // <3>
    "tableChanges": [ // <4>
      {
        "type": "CREATE", // <5>
        "id": "\"DB2INST1\".\"CUSTOMERS\"", // <6>
        "table": { // <7>
          "defaultCharsetName": null,
          "primaryKeyColumnNames": [ // <8>
            "ID"
          ],
          "columns": [ // <9>
            {
              "name": "ID",
              "jdbcType": 4,
              "nativeType": null,
              "typeName": "int identity",
              "typeExpression": "int identity",
              "charsetName": null,
              "length": 10,
              "scale": 0,
              "position": 1,
              "optional": false,
              "autoIncremented": false,
              "generated": false
            },
            {
              "name": "FIRST_NAME",
              "jdbcType": 12,
              "nativeType": null,
              "typeName": "varchar",
              "typeExpression": "varchar",
              "charsetName": null,
              "length": 255,
              "scale": null,
              "position": 2,
              "optional": false,
              "autoIncremented": false,
              "generated": false
            },
            {
              "name": "LAST_NAME",
              "jdbcType": 12,
              "nativeType": null,
              "typeName": "varchar",
              "typeExpression": "varchar",
              "charsetName": null,
              "length": 255,
              "scale": null,
              "position": 3,
              "optional": false,
              "autoIncremented": false,
              "generated": false
            },
            {
              "name": "EMAIL",
              "jdbcType": 12,
              "nativeType": null,
              "typeName": "varchar",
              "typeExpression": "varchar",
              "charsetName": null,
              "length": 255,
              "scale": null,
              "position": 4,
              "optional": false,
              "autoIncremented": false,
              "generated": false
            }
          ]
        }
      }
    ]
  }
}
----

.Descriptions of fields in messages emitted to the schema change topic
[cols="1,3,6",options="header"]
|===
|Item |Field name |Description

|1
|`ts_ms`
|Optional field that displays the time at which the connector processed the event. The time is based on the system clock in the JVM running the Kafka Connect task.

In the source object, ts_ms indicates the time that the change was made in the database. By comparing the value for payload.source.ts_ms with the value for payload.ts_ms, you can determine the lag between the source database update and Debezium.

|2
|`databaseName` +
`schemaName`
|Identifies the database and the schema that contain the change.

|3
|`ddl`
|Always `null` for the Db2 connector.
For other connectors, this field contains the DDL responsible for the schema change.
This DDL is not available to Db2 connectors.

|4
|`tableChanges`
|An array of one or more items that contain the schema changes generated by a DDL command.

|5
|`type`
a|Describes the kind of change. The value is one of the following:

* `CREATE` - table created
* `ALTER` - table modified
* `DROP` - table deleted

|6
|`id`
|Full identifier of the table that was created, altered, or dropped.

|7
|`table`
|Represents table metadata after the applied change.

|8
|`primaryKeyColumnNames`
|List of columns that compose the table's primary key.

|9
|`columns`
|Metadata for each column in the changed table.

|===

In messages that the connector sends to the schema change topic, the message key is the name of the database that contains the schema change.
In the following example, the `payload` field contains the key:

[source,json,indent=0,subs="+attributes"]
----
{
  "schema": {
    "type": "struct",
    "fields": [
      {
        "type": "string",
        "optional": false,
        "field": "databaseName"
      }
    ],
    "optional": false,
    "name": "io.debezium.connector.db2.SchemaChangeKey"
  },
  "payload": {
    "databaseName": "TESTDB"
  }
}
----


